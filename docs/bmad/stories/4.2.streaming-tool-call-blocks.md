---
title: Story 4.2 — Streaming Tool Call Blocks
status: Done
version: 1.2
updated: 2025-09-24
epic: docs/bmad/stories/epic-chat-completions-canonical-parity.md
labels: [streaming, tool_calls, api]
---

## Status

Done — PO validation (2025-09-24) approved via `docs/bmad/qa/assessments/4.2-po-validation-20250924.md`. QA gate `docs/bmad/qa/gates/4.2-streaming-tool-call-blocks.yml` (PASS) and benchmarking confirmed usage buffering introduces ≤0.8 MB RSS delta and <0.05 s CPU overhead (see QA Results). Story 3.11 remains in Draft per `docs/bmad/issues/2025-09-24-story-3-11-follow-up.md`.

Depends on: Story 4.1 — Finish-Reason Canonicalization (Draft).

## Story

**As a** streaming parity owner,  
**I want** our SSE responses to emit OpenAI-compatible `tool_calls` deltas (and reconciled aggregates),  
**so that** clients relying on function-calling streams interoperate with the proxy without code changes.

## Acceptance Criteria

1. Streaming chunks include incremental `delta.tool_calls[{ id, type:"function", function:{ name, arguments_fragment } }]` frames with stable `id` and index ordering until completion, mirroring OpenAI’s delta contract. [Sources: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Lifecycle of a Stream; https://learn.microsoft.com/azure/ai-services/openai/how-to/use-chat-completions#streaming; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming]
2. A consolidated `tool_calls` array (plus `finish_reason:"tool_calls"`) is produced in non-stream responses and the terminal streaming snapshot for each choice, matching OpenAI schema. [Sources: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes; docs/bmad/architecture/sequence-stream.md; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/key-considerations; https://help.openai.com/en/articles/9144669-function-calling]
3. Requests sent with `stream_options.include_usage: true` yield a trailing usage chunk after the final tool-call delta, and handlers propagate usage in both stream and non-stream responses. [Sources: docs/bmad/architecture/sequence-stream.md; https://docs.langfuse.com/reference/openai/streaming#usage; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/key-considerations]
4. Golden transcripts and contract tests cover at least one tool-calling scenario (`stop` and `tool_calls` finish reasons), assert ordered tool-call deltas, and confirm usage emission with `stream_options.include_usage`. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5); https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming]
5. Capability detection ensures the proxy degrades gracefully when the upstream returns `"parallel_tool_calls": false` (sequential aggregation remains correct). [Sources: docs/bmad/architecture/sequence-stream.md; https://learn.microsoft.com/answers/questions/1922186/function-calling-with-streamed-response-is-not-sup]
6. Documentation updates describe the streamed tool-call structure, include payload examples, and call out interactions with `PROXY_STOP_AFTER_TOOLS` / `PROXY_SUPPRESS_TAIL_AFTER_TOOLS` and `stream_options.include_usage`. [Sources: docs/bmad/architecture/sequence-stream.md; docs/openai-chat-completions-parity.md#Streaming Contract; https://docs.langfuse.com/reference/openai/streaming#usage]

## Tasks / Subtasks

- [x] Extend `src/handlers/chat/stream.js` to parse tool-call deltas from Codex proto events, preserve per-index IDs, and forward incremental SSE frames. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; docs/bmad/architecture/sequence-stream.md; docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming]
- [x] Factor a shared aggregator that stitches `tool_calls` deltas into consolidated calls for both stream and non-stream handlers, including fallbacks when `parallel_tool_calls` is unavailable. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/key-considerations; https://learn.microsoft.com/answers/questions/1922186/function-calling-with-streamed-response-is-not-sup]
- [x] Update non-stream handler (`src/handlers/chat/nonstream.js`) to accumulate final `tool_calls` arrays matching OpenAI schema and propagate usage totals. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; https://docs.langfuse.com/reference/openai/streaming#usage]
- [x] Refresh transcripts with a tool-call scenario (`test-results/chat-completions/streaming-tool-call.json`) and link metadata to the research doc; capture both default `tool_choice:"auto"` and forced `tool_choice` paths. [Sources: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5); https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models]
- [x] Expand integration/Playwright contract tests to assert streamed `tool_calls` payloads, sequential fallbacks, and final aggregated results (including usage chunk). [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; tests/integration/chat.contract.streaming.int.test.js; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming]
- [x] Document tool-call streaming behavior (chunks + final aggregates), capability detection, and toggle interplay (`PROXY_STOP_AFTER_TOOLS`, `PROXY_SUPPRESS_TAIL_AFTER_TOOLS`, `stream_options.include_usage`) in `docs/openai-chat-completions-parity.md`. [Sources: docs/bmad/architecture/sequence-stream.md; docs/openai-chat-completions-parity.md#Streaming Contract; https://docs.langfuse.com/reference/openai/streaming#usage]
- [x] Capture a solo-dev smoke harness (curl or Node script) that streams a tool call and persists the raw SSE log for diffing alongside transcripts. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming; https://videosdk.live/docs/api-reference/utilities/openai-response-streaming/best-practices]
- [x] Add UTF-8 safe buffering/validation helper to normalize argument fragments before emission, with unit coverage for multibyte boundaries. [Sources: docs/bmad/qa/assessments/4.2-risk-20250924.md#Risk Summary; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming]
- [x] Automate smoke harness hash diff workflow (store raw SSE log + SHA256, commit under `docs/bmad/qa/artifacts/streaming-tool-call/`) prior to merge. [Sources: docs/bmad/qa/assessments/4.2-risk-20250924.md#Monitoring & Next Steps]
- [x] Benchmark streaming resource envelope with and without usage buffering; document findings/TPS plus `PROXY_TOOL_BLOCK_MAX` guidance in Dev Notes. _(Completed 2025-09-24.)_ [Sources: docs/bmad/qa/assessments/4.2-risk-20250924.md#Mitigations & Owners]
- [x] Instrument `src/dev-logging.js` (or successor telemetry) to emit structured tool-call lifecycle events and surface counts in Langfuse dashboards. [Sources: docs/bmad/qa/assessments/4.2-risk-20250924.md#Mitigations & Owners; https://docs.langfuse.com/reference/openai/streaming#usage]

## Dev Notes

- Streaming handler already tracks tool control flags (`PROXY_STOP_AFTER_TOOLS`, tail suppression); ensure new deltas respect these paths. [Source: docs/bmad/architecture/sequence-stream.md]
- Codex proto emits `agent_message_delta` events containing type/function/arguments; reuse or extend existing parsing logic rather than reimplementing. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- Use the aggregator helper (`src/lib/tool-call-aggregator.js`) to normalize argument fragments via Buffer-backed accumulation and guard against partial UTF-8 chunks before writing to SSE; covered by `tests/unit/tool-call-aggregator.spec.js`. [Source: https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming]
- Non-stream responses should mirror OpenAI’s `tool_calls` shape to keep SDKs (Python/JS) operating without custom adapters. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- Introduce a deterministic fake-codex scenario for tool calls so transcripts and tests remain stable. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]
- For solo development, capture raw SSE logs with the smoke harness (`scripts/smoke/stream-tool-call.js`) and diff against golden transcripts to catch ordering regressions quickly. Artifacts live under `docs/bmad/qa/artifacts/streaming-tool-call/` as `.sse` + `.sha256`. [Source: https://videosdk.live/docs/api-reference/utilities/openai-response-streaming/best-practices]
- Benchmark results (2025-09-24): smoke harness runs with usage buffering on/off completed in ~0.12 s wall time; peak RSS 56.3 MB vs 57.0 MB (∆ 0.7 MB); CPU stayed <0.05 s user/<0.02 s system. Retain default `PROXY_TOOL_BLOCK_MAX`=16 and monitor concurrency after canary.
- Observability: ensure Langfuse spans/logs capture `tool_call_index`, `delta_position`, and `usage_emitted` flags for each stream to aid post-deploy audits. [Sources: docs/bmad/qa/assessments/4.2-risk-20250924.md#Mitigations & Owners]
- Coordinate with telemetry (`src/dev-logging.js`) and Langfuse instrumentation so function-call spans surface in observability dashboards without extra headcount. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; https://docs.langfuse.com/reference/openai/streaming#usage]

## Testing

- `npm run transcripts:generate -- --scenario streaming-tool-call`. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]
- `npm run test:integration -- chat.contract.streaming.int.test.js`. [Source: docs/bmad/architecture/tech-stack.md#Testing & QA]
- `npm test` (Playwright) to validate SSE contract coverage and ordered tool-call deltas. [Source: docs/bmad/architecture/tech-stack.md#Testing & QA]
- `KEY=sk-... node scripts/smoke/stream-tool-call.js --include-usage` to capture a single streamed call, persist the SSE log, and diff against transcripts. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; https://docs.fireworks.ai/api-reference/api-reference/chat-completions/streaming; https://videosdk.live/docs/api-reference/utilities/openai-response-streaming/best-practices]

## QA Results

- 2025-09-24 — QA Review PASS; resource benchmarking recorded usage-buffer on/off envelope (see `docs/bmad/qa/assessments/4.2-review-20250924.md`).
- QA Gate: PASS (`docs/bmad/qa/gates/4.2-streaming-tool-call-blocks.yml`), quality score 93, expires 2025-10-08.
- PO Validation APPROVED (2025-09-24) → `docs/bmad/qa/assessments/4.2-po-validation-20250924.md`.
- Evidence: `npm run test:unit`, `npm run test:integration -- chat.contract.streaming.int.test.js`, `npm test`, `npm run transcripts:generate`, `node scripts/smoke/stream-tool-call.js --include-usage`, `node scripts/smoke/stream-tool-call.js`.

## Change Log

| Date       | Version | Description                                                                                                           | Author  |
| ---------- | ------- | --------------------------------------------------------------------------------------------------------------------- | ------- |
| 2025-09-24 | 1.2     | PO validation approved; status to Done; QA results/evidence updated                                                   | po      |
| 2025-09-24 | 1.1     | Documented benchmarking results and closed PERF-4201 follow-up; updated QA status/evidence                            | qa      |
| 2025-09-24 | 1.0     | QA review & gate PASS; status moved to Ready for PO; tests, transcripts, smoke harness logged                         | qa      |
| 2025-09-24 | 0.3     | Captured risk-driven tasks (UTF-8 safety, smoke harness hashes, benchmarking, telemetry) and linked solo-dev workflow | analyst |
| 2025-09-24 | 0.2     | Added tool-call delta/usage research targets, solo-dev harness, and capability detection                              | analyst |
