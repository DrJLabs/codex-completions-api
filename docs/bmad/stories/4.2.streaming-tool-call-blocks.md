---
title: Story 4.2 — Streaming Tool Call Blocks
status: Draft
version: 0.1
updated: 2025-09-24
epic: docs/bmad/stories/epic-chat-completions-canonical-parity.md
labels: [streaming, tool_calls, api]
---

## Status

Draft — proceeding while Story 3.11 remains in Draft per `docs/bmad/issues/2025-09-24-story-3-11-follow-up.md`.

Depends on: Story 4.1 — Finish-Reason Canonicalization (Draft).

## Story

**As a** streaming parity owner,  
**I want** our SSE responses to emit OpenAI-compatible `tool_calls` deltas (and reconciled aggregates),  
**so that** clients relying on function-calling streams interoperate with the proxy without code changes.

## Acceptance Criteria

1. Streaming chunks include incremental `delta.tool_calls[{ id, type:"function", function:{ name, arguments_fragment } }]` frames until the call completes, matching OpenAI ordering. [Sources: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Lifecycle of a Stream; https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models]
2. A consolidated `tool_calls` array is present in non-stream responses and in the final streaming snapshot for each choice. [Sources: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes; docs/bmad/architecture/sequence-stream.md; https://help.openai.com/en/articles/9144669-function-calling]
3. Golden transcripts and contract tests cover at least one tool-calling scenario (`stop` and `tool_calls` finish reasons) while preserving chunk order and usage emission. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5); https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models]
4. Documentation updates describe the streamed tool-call structure, include payload examples, and call out interactions with `PROXY_STOP_AFTER_TOOLS` / `PROXY_SUPPRESS_TAIL_AFTER_TOOLS`. [Sources: docs/bmad/architecture/sequence-stream.md; docs/openai-chat-completions-parity.md#Streaming Contract]

## Tasks / Subtasks

- [ ] Extend `src/handlers/chat/stream.js` to parse tool-call deltas from Codex proto events and forward them as incremental SSE frames. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; docs/bmad/architecture/sequence-stream.md; docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- [ ] Update non-stream handler (`src/handlers/chat/nonstream.js`) to accumulate final `tool_calls` arrays matching OpenAI schema. [Source: docs/bmad/architecture/source-tree.md#src/ Modules]
- [ ] Refresh transcripts with a tool-call scenario (`test-results/chat-completions/streaming-tool-call.json`) and link metadata to the research doc; capture both default `tool_choice:"auto"` and forced `tool_choice` paths. [Sources: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5); https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models]
- [ ] Expand integration/Playwright contract tests to assert streamed `tool_calls` payloads and final aggregated results. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; tests/integration/chat.contract.streaming.int.test.js]
- [ ] Document tool-call streaming behavior (chunks + final aggregates) and toggle interplay in `docs/openai-chat-completions-parity.md`. [Sources: docs/bmad/architecture/sequence-stream.md; docs/openai-chat-completions-parity.md#Streaming Contract; https://help.openai.com/en/articles/9144669-function-calling]

## Dev Notes

- Streaming handler already tracks tool control flags (`PROXY_STOP_AFTER_TOOLS`, tail suppression); ensure new deltas respect these paths. [Source: docs/bmad/architecture/sequence-stream.md]
- Codex proto emits `agent_message_delta` events containing type/function/arguments; reuse or extend existing parsing logic rather than reimplementing. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- Non-stream responses should mirror OpenAI’s `tool_calls` shape to keep SDKs (Python/JS) operating without custom adapters. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- Introduce a deterministic fake-codex scenario for tool calls so transcripts and tests remain stable. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]
- For solo development, reuse the cookbook streaming sample to capture before/after JSON for manual regression diffing and to validate that frame order matches reference output. [Source: https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models]
- Coordinate with telemetry (`src/dev-logging.js`) if new event types need logging for observability. [Source: docs/bmad/architecture/source-tree.md#src/ Modules]

## Testing

- `npm run transcripts:generate -- --scenario streaming-tool-call`. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]
- `npm run test:integration -- chat.contract.streaming.int.test.js`. [Source: docs/bmad/architecture/tech-stack.md#Testing & QA]
- `npm test` (Playwright) to validate SSE contract coverage. [Source: docs/bmad/architecture/tech-stack.md#Testing & QA]

## QA Results

Pending

## Change Log

| Date       | Version | Description                                 | Author |
| ---------- | ------- | ------------------------------------------- | ------ |
| 2025-09-24 | 0.1     | Initial draft covering streaming tool calls | sm     |
