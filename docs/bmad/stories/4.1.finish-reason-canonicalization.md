---
title: Story 4.1 — Finish-Reason Canonicalization
status: Done
version: 1.0
updated: 2025-09-24
epic: docs/bmad/stories/epic-chat-completions-canonical-parity.md
labels: [api, streaming, nonstream, finish_reason]
---

## Status

Done — 2025-09-24 (merged PRs #98, #99). Follow-up issue `docs/bmad/issues/2025-09-24-story-3-11-follow-up.md` tracks the remaining SIGTERM QA story sequencing.

Depends on: Story 3.9 — Streaming Finalizer Richer finish_reason (Done 2025-09-22).

## Story

**As a** chat completions parity owner,  
**I want** non-stream and streaming responses to normalize the full set of OpenAI finish reasons,  
**so that** downstream clients interpret moderation, tool-call, and truncation outcomes identically to OpenAI.

## Acceptance Criteria

1. Non-stream `/v1/chat/completions` responses surface `finish_reason` values `stop`, `length`, `tool_calls`, `content_filter`, and legacy `function_call` when provided by upstream metadata. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Lifecycle of a Stream]
2. Streaming finalizer chunks emit the same canonical `finish_reason` values while intermediate deltas keep `finish_reason:null`. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Lifecycle of a Stream]
3. Golden transcripts and contract tests cover representative `stop`, `length`, `tool_calls`, and `content_filter` cases without altering ordering (role → content → finish → optional usage → `[DONE]`). [Sources: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Lifecycle of a Stream; docs/openai-chat-completions-parity.md#Streaming Contract]
4. Forced tool execution (`tool_choice:"required"` or explicit function selection) is handled safely by relying on the presence of `tool_calls` rather than only the `finish_reason`, because OpenAI responses may still return `finish_reason:"stop"` when the tool payload completed. [Source: https://community.openai.com/t/function-call-with-finish-reason-of-stop/437226/5]
5. Documentation updates introduce a finish-reason matrix citing the canonical set and call out legacy `function_call` handling for backward compatibility. [Source: docs/openai-chat-completions-parity.md#Streaming Contract]

## Tasks / Subtasks

- [x] Audit upstream metadata plumbing in `src/handlers/chat/nonstream.js` and `src/handlers/chat/stream.js`; map provider reasons to canonical values with fallbacks. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- [x] Extend finish-reason normalization helper (or add one) shared by both handlers to avoid drift. [Sources: src/utils.js; docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- [x] Refresh streaming/non-stream golden transcripts (`test-results/chat-completions/*.json`) with new scenarios using `npm run transcripts:generate`. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]
- [x] Update `tests/integration/chat.contract.streaming.int.test.js` and non-stream shape tests for expanded finish-reason expectations, including cases where `tool_calls` is populated despite `finish_reason:"stop"`. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; https://community.openai.com/t/function-call-with-finish-reason-of-stop/437226/5]
- [x] Document finish-reason matrix adjustments in `docs/openai-chat-completions-parity.md` and new research reference linkage. [Sources: docs/openai-chat-completions-parity.md#Streaming Contract; docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Field Notes]
- [x] Instrument canonical finish-reason telemetry (structured logging + metrics) across non-stream and streaming handlers so distribution can be monitored in staging/prod dashboards. [Source: docs/bmad/qa/assessments/4.1-risk-20250924.md#Risk Profile: Story 4.1 — Finish-Reason Canonicalization]

## Dev Notes

- Streaming handler (`src/handlers/chat/stream.js`) consumes Codex proto events and emits SSE envelopes, so finish-reason mapping must integrate before the finalizer chunk is sent. [Sources: docs/bmad/architecture/source-tree.md#src/ Modules; docs/bmad/architecture/sequence-stream.md]
- Non-stream handler (`src/handlers/chat/nonstream.js`) already aggregates upstream messages; extend the same mapper to ensure parity with streaming values. [Source: docs/bmad/architecture/source-tree.md#src/ Modules]
- The canonical streaming lifecycle ensures role delta → content deltas → finish-reason chunk → optional usage chunk → `[DONE]`; avoid reordering when introducing new finish reasons. [Source: docs/bmad/research/2025-09-24-openai-chat-completions-streaming-reference.md#Lifecycle of a Stream]
- Golden transcripts live under `test-results/chat-completions/` and serve contract tests; update placeholders (`<dynamic-id>`, `<timestamp>`) only if structure changes. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]
- Solo-dev safeguard: capture a short streaming session using the cookbook sample collector to replay locally before/after code changes, so regressions can be reproduced without team reviewers. [Source: https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models]
- Reference prior finish-reason work in Story 3.9 for implementation approach and regression risks. [Source: docs/bmad/stories/3.9.streaming-finalizer-finish-reason.md]
- Instrumentation guidance: log canonical finish reasons via existing telemetry hooks and expose distribution metrics to catch unexpected spikes (Risk OBS-4101). [Source: docs/bmad/qa/assessments/4.1-risk-20250924.md]
- Testing modernization support: apply Playwright fixture/tracing updates and Vitest diff-based + nightly coverage practices outlined in docs/bmad/research/2025-09-24-testing-design-modernization.md.

## Testing

- Local loop: `vitest --changed` for fast feedback; run full suite with `npm run verify:all` when major mapper updates land. [Source: docs/bmad/qa/assessments/4.1-test-design-20250924.md]
- Nightly coverage: schedule `vitest run --coverage` to track canonicalization drift without slowing daily work. [Source: docs/bmad/qa/assessments/4.1-test-design-20250924.md]
- Streaming harness: `npx playwright test tests/playwright/chat.streaming.spec.ts --trace on-first-retry` with worker fixtures enabled for deterministic telemetry, alongside `npm run test:integration -- chat.contract.streaming.int.test.js`. [Source: docs/bmad/qa/assessments/4.1-test-design-20250924.md]
- Golden assets: `npm run transcripts:generate` before contract tests to refresh non-stream/stream fixtures. [Source: docs/openai-chat-completions-parity.md#Golden Transcripts & Snapshots (Story 3.5)]

## QA Results

- 2025-09-24 — Risk Profile documented (Quinn, QA) → docs/bmad/qa/assessments/4.1-risk-20250924.md.
- 2025-09-24 — Test Design documented (Quinn, QA) → docs/bmad/qa/assessments/4.1-test-design-20250924.md.
- 2025-09-24 — PO Validation (Sarah, PO) → docs/bmad/qa/assessments/4.1-po-validation-20250924.md.
- 2025-09-24 — Traceability Matrix documented (Quinn, QA) → docs/bmad/qa/assessments/4.1-trace-20250924.md.
- 2025-09-24 — NFR Assessment documented (Quinn, QA) → docs/bmad/qa/assessments/4.1-nfr-20250924.md.
- 2025-09-24 — QA Gate PASS (Quinn, QA) → docs/bmad/qa/gates/4.1-finish-reason-canonicalization.yml.

## Dev Agent Record

- Agent Model Used: codex-5
- Debug Log References: `.tmp-usage.test.ndjson` (captures appendUsage entries for streaming/non-stream scenarios)
- Completion Notes:
  - Introduced `createFinishReasonTracker` in `src/handlers/chat/shared.js` to canonicalize upstream reasons, record source priority, and emit structured telemetry with `logFinishReasonTelemetry`.
  - Refactored `src/handlers/chat/nonstream.js` and `src/handlers/chat/stream.js` to share the tracker, merge tool/function call payloads, suppress content for `tool_calls`/`function_call`/`content_filter`, and fall back to `length` when Codex exits without `task_complete`.
  - Expanded the fake proto shim to emit `tool_call`, `function_call`, and `content_filter` scenarios (`scripts/fake-codex-proto.js`) and updated the transcript generator to snapshot new variants plus re-baseline existing goldens.
  - Regenerated chat completion transcripts covering `stop`, `length`, `tool_calls`, `content_filter`, and legacy `function_call` cases via `npm run transcripts:generate`.
  - Hardened integration suites to assert canonical finish reasons across non-stream and streaming paths and refreshed LangChain harness coverage; ran `npm run verify:all` (format, lint, unit, integration, Playwright).
- File List:
  - `src/handlers/chat/shared.js`
  - `src/handlers/chat/nonstream.js`
  - `src/handlers/chat/stream.js`
  - `scripts/fake-codex-proto.js`
  - `scripts/generate-chat-transcripts.mjs`
  - `docs/openai-chat-completions-parity.md`
  - `docs/bmad/architecture.md`
  - `docs/bmad/prd.md`
  - `tests/integration/chat.nonstream.shape.int.test.js`
  - `tests/integration/chat.contract.streaming.int.test.js`
  - `tests/integration/nonstream.fields.int.test.js`
  - `tests/shared/transcript-utils.js`
  - `test-results/chat-completions/*.json`

## Change Log

| Date       | Version | Description                                                 | Author |
| ---------- | ------- | ----------------------------------------------------------- | ------ |
| 2025-09-24 | 1.0     | Story complete; guard alignment, docs, and telemetry live   | dev    |
| 2025-09-24 | 0.2     | Implementation, tests, and docs for canonical finish_reason | dev    |
| 2025-09-24 | 0.1     | Initial draft for canonical reasons                         | sm     |
