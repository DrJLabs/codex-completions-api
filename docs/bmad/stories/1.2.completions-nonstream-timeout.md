---
title: Story 1.2 — Bug: /v1/completions non‑stream timeout
status: Draft
version: 0.1
updated: 2025-09-11
epic: docs/bmad/stories/epic-server-modularization-refactor.md
---

## Story

As a user of the legacy `/v1/completions` endpoint (non‑stream), I want the request to complete within the configured timeout so that clients relying on non‑stream behavior don’t hang.

## Reproduction

- Request: `POST /v1/completions` with `{ model: "gpt-5", stream: false, prompt: "Say hello." }`
- Auth: `Authorization: Bearer <PROXY_API_KEY>`
- Observed: Response fails with `{"error":{"message":"backend idle timeout",...}}` within ~20s (curl max-time 60s).
- Expected: OpenAI‑shaped JSON with `choices[0].text` and `usage`.

## Hypothesis

- The non‑stream completions aggregator path isn’t emitting within `PROTO_IDLE_MS`/`REQ_TIMEOUT_MS` or diverges from the working chat non‑stream path.

## Acceptance Criteria

1. Non‑stream `/v1/completions` returns a JSON payload under default timeouts for a short prompt.
2. Response shape matches chat‑mapped semantics (object/text fields as implemented).
3. PRD smoke for non‑stream completions passes locally.
4. No regressions to chat (stream/non‑stream) or streaming completions.

## Tasks

- [ ] Compare completions vs chat non‑stream spawn args and aggregation loop.
- [ ] Align aggregator behavior to chat path (headers, timeouts, usage calc).
- [ ] Add targeted integration test (supertest) for `/v1/completions` non‑stream.
- [ ] Update PRD success examples if object naming differs from chat.

## Notes

- Streaming for `/v1/completions` works; only non‑stream path times out.
- Priority: Low (most clients use `/v1/chat/completions`).
