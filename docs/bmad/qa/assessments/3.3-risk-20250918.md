---
title: Risk Profile — Story 3.3 (Streaming Usage Early Emission)
story: docs/bmad/stories/3.3.streaming-usage-early-emission.md
date: 2025-09-18
reviewer: Quinn (Test Architect)
labels: [qa, risk, streaming, usage, sse, stability]
---

# Risk Profile: Story 3.3 — Streaming Usage Early Emission

Date: 2025-09-18  
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 9
- Critical Risks: 0
- High Risks: 1 (TECH-101 — incorrect usage ordering in live streams)
- Medium Risks: 5
- Low Risks: 3
- Overall Story Risk Score: Medium — requires targeted regression + telemetry validation

## Risk Summary (Gate YAML)

```yaml
risk_summary:
  totals:
    critical: 0
    high: 1
    medium: 5
    low: 3
  highest:
    id: TECH-101
    score: 6
    title: Streaming usage chunk emitted before finish_reason
  recommendations:
    must_fix:
      - Preserve OpenAI contract ordering by gating emission flush behind finish_reason frame when `token_count` fires
      - Add automated regression to fail if usage chunk precedes finish_reason in SSE transcript
    monitor:
      - Track duplicate usage events in dev/prod usage NDJSON for 72h post deploy
      - Watch billing dashboards for unexpected spikes caused by emission trigger tagging
      - Compare include_usage=false traffic for surprise usage payloads and ensure handler deduplicates
```

## Risk Register

| Risk ID  | Category    | Description                                                                                                        | Prob | Impact | Score | Priority |
| -------- | ----------- | ------------------------------------------------------------------------------------------------------------------ | ---- | ------ | ----- | -------- |
| TECH-101 | Technical   | Handler emits usage chunk before finish_reason, breaking OpenAI contract clients and replay/parity tooling         | 2    | 3      | 6     | High     |
| TECH-102 | Technical   | Duplicate usage chunks logged when both `token_count` and late `task_complete` fire, causing double billing counts | 2    | 2      | 4     | Medium   |
| TECH-103 | Technical   | Usage metadata (emission trigger/timestamps) missing or inconsistent, reducing observability for early exits       | 2    | 2      | 4     | Medium   |
| TECH-105 | Technical   | Upstream provider emits usage chunk even when `include_usage:false`, risking double responses or schema drift      | 2    | 2      | 4     | Medium   |
| TECH-104 | Technical   | Failure to emit usage when stream aborts without `task_complete` (child crash, timeout)                            | 1    | 3      | 3     | Medium   |
| PERF-101 | Performance | Extra flushes increase stream latency or CPU due to repeated JSON serialization                                    | 1    | 2      | 2     | Low      |
| DATA-101 | Data        | Emission trigger metadata reveals sensitive request identifiers in logs                                            | 1    | 2      | 2     | Low      |
| OPS-101  | Operational | Billing dashboards or analytics pipelines mis-handle new metadata fields                                           | 1    | 2      | 2     | Low      |
| TEST-101 | Testing     | Existing SSE contract tests do not assert for duplicate usage or trigger metadata                                  | 2    | 2      | 4     | Medium   |

## Mitigations & Owners

- TECH-101: Implement guard to buffer usage until after finish_reason frame; add Playwright assertion verifying order. Owner: Dev.
- TECH-102: Maintain single-write guard in handler; add integration regression simulating `token_count` + trailing `task_complete`. Owner: Dev/QA.
- TECH-103: Extend `appendUsage` logging with `emission_trigger`, `emitted_at_ms`; unit test serialization and schema. Owner: Dev.
- TECH-104: Simulate child exit/abort in integration harness; confirm fallback usage flush executes. Owner: QA.
- TECH-105: Add regression covering include_usage=false requests that still receive usage payloads; ensure handler ignores provider-sent usage when we already emitted one. Owner: Dev/QA.
- PERF-101: Capture stream latency metrics before/after change; ensure acceptable delta (<5%). Owner: Dev.
- DATA-101: Review metadata payload; ensure no raw API keys or user content included. Owner: Dev/QA.
- OPS-101: Coordinate with analytics consumers, update schema docs, and verify dashboards. Owner: PM/Analytics.
- TEST-101: Expand contract tests to assert usage ordering, metadata presence, and duplicate prevention. Owner: QA.

## Risk-Based Testing Focus

- Priority 1: Streaming SSE transcript assertions (order + single usage), integration coverage for abort/timeout, duplicate-prevention regression, and include_usage=false provider drift scenario.
- Priority 2: Logging/telemetry schema validation (`appendUsage` unit test), analytics smoke verifying dashboards ingest new fields.
- Priority 3: Performance sampling (latency impact) and documentation lint to confirm instructions reach runbooks.

## Monitoring Requirements

- Add temporary dashboard tracking count of usage events per request ID to detect duplicates.
- Monitor dev/prod usage NDJSON for `emission_trigger` distribution (token_count vs task_complete vs provider) to validate instrumentation.
- Watch billing/analytics pipeline error rates for schema mismatch after deployment.

## References

- Story: docs/bmad/stories/3.3.streaming-usage-early-emission.md
- PRD: docs/bmad/prd.md#POST /v1/chat/completions
- Architecture (stream handler): docs/bmad/architecture.md#Chat — Stream (SSE)
- Sequence diagram: docs/bmad/architecture/sequence-stream.md
- OpenAI streaming contract update (2024-05-06) and 2025 community regression notes (see Story Dev Notes)
- Provider drift report: https://github.com/sashabaranov/go-openai/issues/1021 (2025-06-17)

**Hook:** `Risk profile: docs/bmad/qa/assessments/3.3-risk-20250918.md`
