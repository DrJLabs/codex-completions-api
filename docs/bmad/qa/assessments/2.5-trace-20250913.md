---
title: Requirements Traceability Matrix — Story 2.5 (Non‑Stream Tidy)
story: docs/bmad/stories/2.5.phase-f-non-stream-tidy.md
epic: docs/bmad/stories/epic-openai-chat-completions-parity.md
date: 2025-09-13
owner: QA
---

## Scope

Map each acceptance criterion (AC) to tests and artifacts ensuring non‑stream response parity (`finish_reason`, `usage`, and `model` consistency).

## Matrix

- AC‑1 Non‑stream response shape parity + usage present
  - Tests:
    - tests/integration/chat.nonstream.shape.int.test.js — object/model/message/usage + stop finish_reason.
  - Artifact: docs/openai-chat-completions-parity.md (Non‑Stream Response section)
  - Status: COVERED

- AC‑2 `finish_reason` mapping (stop vs length)
  - Tests:
    - tests/integration/chat.nonstream.shape.int.test.js — normal completion → `stop`.
    - tests/integration/chat.nonstream.length.int.test.js — simulated truncation (no task_complete) → `length`.
  - Status: COVERED

- AC‑3 `model` consistency with streaming path
  - Tests:
    - tests/integration/chat.model.consistency.int.test.js — first stream chunk vs non‑stream response `model` equality.
  - Status: COVERED

## Given‑When‑Then Snippets

- Given a minimal prompt, when posting non‑stream, then response has `object:"chat.completion"`, `choices[0].message.role:"assistant"`, `usage` present, and `finish_reason:"stop"`.
- Given backend exits without `task_complete`, when posting non‑stream, then `finish_reason:"length"` and `usage` present via estimator.
- Given same prompt and model, when posting stream and non‑stream, then `model` strings are equal.

## Coverage Summary

- Coverage: FULL
- Notes: No code changes required; parity validated via integration tests.
