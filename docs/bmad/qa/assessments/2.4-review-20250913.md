---
title: QA Review — Story 2.4 (Phase E: Error Response Parity)
story: docs/bmad/stories/2.4.phase-e-error-response-parity.md
date: 2025-09-13
owner: Quinn (Test Architect)
---

## Summary

Scope addresses error envelope parity for `/v1/chat/completions` across non‑stream and streaming paths. Implementation centralizes helpers, adds `n>1` and context‑length guards, normalizes streaming error frames, updates spec/docs, and provides integration tests. All suites are green.

Decision: PASS

## Evidence

- Code: `src/lib/errors.js` (helpers), `src/handlers/chat/{nonstream,stream}.js` (validations + SSE error normalization), `src/config/index.js` (`PROXY_MAX_PROMPT_TOKENS`).
- Tests: integration (invalid‑n, context‑length, rate‑limit), server auth/404, existing param test; E2E unchanged and green.
- Docs: `docs/openai-chat-completions-parity.md` updated (Streaming Errors section).
- QA: Risk, Test Design, Trace, NFR for 2.4 present and linked from the story.

## Acceptance Criteria Review

- Error envelope shape `{ error: { message, type, code?, param? } }` → MET
- HTTP status/type mapping 400/401/403/404/429/500 → MET (500 via streaming normalization + existing timeout path)
- `param` on validation failures (`messages`, `model`, `n`) → MET
- Unknown optionals ignored → MET (policy unchanged)
- Tests and docs updated → MET

## Notes & Recommendations

- Consider adding a targeted 500 integration test that simulates an internal server error on non‑stream for completeness (non‑blocking).
- If/when permission rules exist, use `permission_error` helper to keep mapping consistent.

## Gate

- See: `docs/bmad/qa/gates/2.4-phase-e-error-response-parity.yml`
